{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all needed packages/libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import copy\n",
    "import operator\n",
    "import pandas\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import nltk.stem\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize,sent_tokenize\n",
    "from nltk import SnowballStemmer\n",
    "from gensim import corpora,models,similarities\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from collections import defaultdict\n",
    "import operator\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The implementation of textual content model, please use different time intervals [2,7,14,30] to set the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter=nltk.PorterStemmer()\n",
    "st = LancasterStemmer()\n",
    "st.stem('stemmed')\n",
    "\n",
    "english_punctuations = [',', '.', ':', ';', '?', '(', ')', '[', ']', '&', '!', '*', '@', '#', '$', '%']\n",
    "s = nltk.stem.SnowballStemmer('english')\n",
    "\n",
    "dic1 = {}\n",
    "acc=[]\n",
    "rank = []\n",
    "score = []\n",
    "position = []\n",
    "output= []\n",
    "dict_result = {}\n",
    "count = 1\n",
    "candidate_all = []\n",
    "\n",
    "data_test = pandas.read_csv('')    #import ground truth dataset file in the textual content folder\n",
    "\n",
    "data_train = pandas.read_excel('') #import experiment dataset file in the textual content folder\n",
    "data_train = data_train.dropna()\n",
    "with open('') as csvfile:          #impot pair_match file in the textual content folder\n",
    "    read = csv.reader (csvfile, delimiter=',')\n",
    "    for row in read:\n",
    "        review1 = row[0]\n",
    "        review2 = row[1]\n",
    "        dic1[review1] = review2\n",
    "\n",
    "##### construct the ground-truth dataset based on time intervals ######\n",
    "\n",
    "test_threshold = data_test[\"Time_diff\"] <= x # tune time intervals [2,7,14,30], note that here the number should -1 as we did the round number of the time diff. \n",
    "data_test = data_test.loc[test_threshold]\n",
    "data_test = data_test.reset_index(drop=True)\n",
    "\n",
    "all_test_reviewid = data_test.Id.tolist()\n",
    "all_test = data_test.Message.tolist()\n",
    "all_test_time = data_test.Time.tolist()\n",
    "test_time_dic = dict(zip(all_test_reviewid,all_test_time))\n",
    "test_text_dic = dict(zip(all_test_reviewid, all_test))\n",
    "\n",
    "###### construct the textual content model ###### \n",
    "\n",
    "for i in range(len(all_test_reviewid)):\n",
    "    \n",
    "##### construct the experiment dataset for each ground truth ########\n",
    "\n",
    "    count = list(test_text_dic.items())[i][0]\n",
    "    all_train_reviewid = []\n",
    "    all_train = []\n",
    "    all_doc_list = []\n",
    "    candidate = []\n",
    "    train_new = pandas.DataFrame()\n",
    "    stamp = list(test_text_dic.items())[i][0]\n",
    "    test_time = pandas.to_datetime(test_time_dic[stamp])         \n",
    "    days = datetime.timedelta(x) # tune time intervals [2,7,14,30] \n",
    "    new_test = test_time - days\n",
    "    interval = (pandas.to_datetime(data_train['Time']) < test_time) & (pandas.to_datetime(data_train['Time']) > new_test)\n",
    "    train_new = data_train.loc[interval]\n",
    "    train_new = train_new.reset_index(drop=True)\n",
    "    index = train_new.index\n",
    "    number_of_rows = len(index) # in order to print the experiment dataset sizes\n",
    "    for element in train_new['Id']:\n",
    "        all_train_reviewid.append(element)\n",
    "    for message in train_new['Message']:\n",
    "        all_train.append(message) \n",
    "    \n",
    "###### construct the textual corpus and apply tf-idf #######\n",
    "\n",
    "    for doc in all_train:\n",
    "        doc_token = [word for word in nltk.word_tokenize(doc)]\n",
    "        doc_stop = [w for w in doc_token if(w.lower() not in stopwords.words('english'))]\n",
    "        doc_punctuations = [w for w in doc_stop if w not in english_punctuations]  \n",
    "        doc_stemmed=[porter.stem(t) for t in doc_punctuations]\n",
    "        all_doc_list.append(doc_stemmed)\n",
    "    dictionary = corpora.Dictionary(all_doc_list)\n",
    "    dictionary.keys()\n",
    "    dictionary.token2id\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in all_doc_list]\n",
    "    tfidf = models.TfidfModel(corpus)    \n",
    "    doc_test_token = [word for word in nltk.word_tokenize(list(test_text_dic.items())[i][1])]\n",
    "    doc_test_stop = [w for w in doc_test_token if(w.lower() not in stopwords.words('english'))]\n",
    "    doc_test_punctuations = [w for w in doc_test_stop if w not in english_punctuations]\n",
    "    doc_test_stemmed=[porter.stem(t) for t in doc_test_punctuations]\n",
    "    doc_test_vec = dictionary.doc2bow(doc_test_stemmed)\n",
    "    tfidf[doc_test_vec]\n",
    "    index = similarities.SparseMatrixSimilarity(tfidf[corpus], num_features=len(dictionary.keys()))\n",
    "    sim = index[tfidf[doc_test_vec]]\n",
    "    sim = sorted(enumerate(sim), key=lambda item: (-item[1], -item[0]))\n",
    "    \n",
    "###### retrieve Top-10 candidate list and do the matching whether or not each ground truth is detected #######\n",
    "    sim = sim[:10]\n",
    "    \n",
    "    for i in range(0,len(sim)):\n",
    "        candidate.extend([str(all_train_reviewid[sim[i][0]])])\n",
    "        \n",
    "    candidate_all.append(candidate)\n",
    "    \n",
    "    if (str(dic1[str(count)]) == str(candidate[0])):           \n",
    "            acc.append(1)\n",
    "            score.append(1)\n",
    "            output.append(count)\n",
    "            rank.append(1)\n",
    "        \n",
    "    elif (str(dic1[str(count)]) == str(candidate[1])):\n",
    "            acc.append(1)\n",
    "            score.append(1/2)\n",
    "            output.append(count)\n",
    "            rank.append(2)\n",
    "        \n",
    "    elif (str(dic1[str(count)]) == str(candidate[2])):\n",
    "            acc.append(1)\n",
    "            score.append(1/3)\n",
    "            output.append(count)\n",
    "            rank.append(3)\n",
    "        \n",
    "    elif (str(dic1[str(count)]) == str(candidate[3])):\n",
    "            acc.append(1)\n",
    "            score.append(1/4)\n",
    "            output.append(count)\n",
    "            rank.append(4)\n",
    "        \n",
    "    elif (str(dic1[str(count)]) == str(candidate[4])):\n",
    "            acc.append(1)\n",
    "            score.append(1/5)\n",
    "            output.append(count)\n",
    "            rank.append(5)\n",
    "        \n",
    "    elif (str(dic1[str(count)]) == str(candidate[5])):\n",
    "            acc.append(1)\n",
    "            score.append(1/6)\n",
    "            output.append(count)\n",
    "            rank.append(6)\n",
    "        \n",
    "    elif (str(dic1[str(count)]) == str(candidate[6])):\n",
    "            acc.append(1)\n",
    "            score.append(1/7)\n",
    "            output.append(count)\n",
    "            rank.append(7)\n",
    "        \n",
    "    elif (str(dic1[str(count)]) == str(candidate[7])):\n",
    "            acc.append(1)\n",
    "            score.append(1/8)\n",
    "            output.append(count)\n",
    "            rank.append(8)\n",
    "        \n",
    "    elif (str(dic1[str(count)]) == str(candidate[8])):\n",
    "            acc.append(1)\n",
    "            score.append(1/9)\n",
    "            output.append(count)\n",
    "            rank.append(9)\n",
    "        \n",
    "    elif (str(dic1[str(count)]) == str(candidate[9])):\n",
    "            acc.append(1)\n",
    "            score.append(1/10)\n",
    "            output.append(count)\n",
    "            rank.append(10)\n",
    "        \n",
    "    else: \n",
    "            acc.append(0)\n",
    "            score.append(0)\n",
    "            output.append(count)\n",
    "            rank.append(0)\n",
    "\n",
    "    print (count, acc[i])\n",
    "    \n",
    "####### map ground truth to their corresponding outputs (i.e., rank), \n",
    "####### and get the Top-10 candidates from the textual content model #######\n",
    "\n",
    "diction = dict(zip(output, rank))\n",
    "candidate_patch = dict(zip(output,candidate_all))\n",
    "score_output = dict(zip(output, score))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The implementation of file location model, please use different time intervals [2,7,14,30] to set the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### define all functions that are used including file string related and borda count\n",
    "\n",
    "def path2List(fileString):\n",
    "    return fileString.split(\"/\");\n",
    "\n",
    "def sort_by_value(d):\n",
    "    items = d.items();\n",
    "    backitem = [[v[1],str(v[0])] for v in items];\n",
    "    backitem.sort(reverse = True);\n",
    "    return [[backitem[i][1],backitem[i][0]] for i in range(0,len(backitem))];\n",
    "\n",
    "def LCP(f1,f2):\n",
    "    f1 = path2List(f1);\n",
    "    f2 = path2List(f2);\n",
    "    common_path = 0;\n",
    "    min_length = min(len(f1),len(f2));\n",
    "    for i in range(min_length):\n",
    "        if f1[i] == f2[i]:\n",
    "            common_path += 1;\n",
    "        else:\n",
    "            break;\n",
    "    return common_path;\n",
    "\n",
    "def filePathSimilarity_LCP(fn,fp):\n",
    "    length_n = len(path2List(fn))\n",
    "    length_p = len(path2List(fp))\n",
    "    return LCP(fn,fp) / max(length_n,length_p);\n",
    "\n",
    "\n",
    "def LCSuff(f1,f2):\n",
    "    f1 = path2List(f1)\n",
    "    f2 = path2List(f2)\n",
    "    common_path = 0\n",
    "    r = list(range(min(len(f1),len(f2))))\n",
    "    r.reverse()\n",
    "    for i in r:\n",
    "        if f1[i] == f2[i]:\n",
    "            common_path += 1\n",
    "        else:\n",
    "            break\n",
    "    return common_path\n",
    "\n",
    "def filePathSimilarity_LCSuff(fn,fp):\n",
    "    length_n = len(path2List(fn))\n",
    "    length_p = len(path2List(fp))\n",
    "    return LCSuff(fn,fp) / max(length_n,length_p);\n",
    "\n",
    "def LCSubstr(f1,f2):\n",
    "    f1 = path2List(f1)\n",
    "    f2 = path2List(f2)\n",
    "    common_path = 0\n",
    "    if len( set(f1) & set(f2)) > 0:\n",
    "        mat = [[0 for x in range(len(f2)+1)] for x in range(len(f1)+1)]\n",
    "        for i in range(len(f1)+1):\n",
    "            for j in range(len(f2)+1):\n",
    "                if i == 0 or j == 0:\n",
    "                    mat[i][j] = 0\n",
    "                elif f1[i-1] == f2[j-1]:\n",
    "                    mat[i][j] = mat[i-1][j-1] + 1\n",
    "                    common_path = max(common_path,mat[i][j])\n",
    "                else:\n",
    "                    mat[i][j] = 0\n",
    "    return common_path\n",
    "\n",
    "def filePathSimilarity_LCSubstr(fn,fp):\n",
    "    length_n = len(path2List(fn))\n",
    "    length_p = len(path2List(fp))\n",
    "    return LCSubstr(fn,fp) / max(length_n,length_p);\n",
    "\n",
    "def LCSubseq(f1,f2):\n",
    "    f1 = path2List(f1)\n",
    "    f2 = path2List(f2)\n",
    "    if len( set(f1) & set(f2)) > 0:\n",
    "        L = [[0 for x in range(len(f2)+1)] for x in range(len(f1)+1)]\n",
    "        for i in range(len(f1)+1):\n",
    "            for j in range(len(f2)+1):\n",
    "                if i == 0 or j == 0:\n",
    "                    L[i][j] = 0\n",
    "                elif f1[i-1] == f2[j-1]:\n",
    "                    L[i][j] = L[i-1][j-1] + 1\n",
    "                else:\n",
    "                    L[i][j] = max(L[i-1][j], L[i][j-1])\n",
    "        common_path = L[len(f1)][len(f2)]\n",
    "    else:\n",
    "        common_path = 0\n",
    "    return common_path\n",
    "\n",
    "def filePathSimilarity_LCSubseq(fn,fp):\n",
    "    length_n = len(path2List(fn))\n",
    "    length_p = len(path2List(fp))\n",
    "    return LCSubseq(fn,fp) / max(length_n,length_p);\n",
    "\n",
    "############### combine the file string techniques using assigned scores and time order ##############\n",
    "\n",
    "def borda_count(dict_result, dict_result_2, dict_result_3, dict_result_4, result1_len): \n",
    "    score_dic = copy.deepcopy(dict_result)\n",
    "    for key in score_dic:\n",
    "        score_dic[key] = defaultdict(list)\n",
    "    \n",
    "    for key in dict_result:\n",
    "        for i in dict_result[key]:\n",
    "            score_dic[key][i].append(result1_len - dict_result[key].index(i))\n",
    "        for i in dict_result_2[key]:\n",
    "            score_dic[key][i].append(result1_len - dict_result_2[key].index(i))\n",
    "        for i in dict_result_3[key]:\n",
    "            score_dic[key][i].append(result1_len - dict_result_3[key].index(i))\n",
    "        for i in dict_result_4[key]:\n",
    "            score_dic[key][i].append(result1_len - dict_result_4[key].index(i))\n",
    "\n",
    "    score_dic_top = copy.deepcopy(score_dic)\n",
    "    for key in score_dic:\n",
    "        sums = []\n",
    "        for key2 in score_dic[key]:\n",
    "            sums.append([key2, sum(score_dic[key][key2])])\n",
    "        for item in sums:\n",
    "            item.append(dict_tc[item[0]])\n",
    "        sums.sort(key=lambda x: [x[1],x[2]],reverse=True)\n",
    "        sums = sums[:10]\n",
    "        for item in sums:\n",
    "            item =item.pop()\n",
    "        sums = np.array(sums)\n",
    "        sums, a = np.hsplit(sums,2)\n",
    "        score_dic_top[key] = [j for sub in sums for j in sub]\n",
    "    return score_dic_top\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "test = list(csv.reader(open(''))); #import ground truth dataset file in the file location folder\n",
    "train = pandas.read_csv(''); #import experiment dataset file in the file location folder\n",
    "#train1 = pandas.read_excel(''); #Note that for Qt and AOSP, as the datasets are too large, need to import two part\n",
    "#train2 = pandas.read_excel('');\n",
    "#train = pd.concat([train1, train2], ignore_index=True, sort=False)\n",
    "checklist = list(csv.reader(open(''))) #import pair_match file in the file location folder\n",
    "test_time = list(csv.reader(open(''))) #import test_time file in the file location folder\n",
    "test.pop(0);\n",
    "test_time.pop(0)\n",
    "checklist.pop(0)\n",
    "\n",
    "dict_a = {};\n",
    "dict_t = {}\n",
    "hit = []\n",
    "position = []\n",
    "\n",
    "##### construct the ground-truth dataset based on time intervals ######\n",
    "\n",
    "for row_a in test:\n",
    "    if int(row_a[2]) <= x: # tune time intervals [2,7,14,30], note that here the number should -1 as we did the round number of the time diff\n",
    "        if row_a[0] not in dict_a:\n",
    "            dict_a[row_a[0]] = [];\n",
    "        dict_a[row_a[0]].append(row_a[1]);\n",
    "    \n",
    "for row_t in test_time:\n",
    "    if row_t[0] not in dict_t:\n",
    "        dict_t[row_t[0]] = [];\n",
    "    dict_t[row_t[0]].append(row_t[1]);\n",
    "    \n",
    "for index, row in data_train.iterrows():\n",
    "    dict_tc[str(row[\"Id\"])]=pd.to_datetime(row[\"Time\"])\n",
    "\n",
    "count = []\n",
    "candidate_all2 = []\n",
    "\n",
    "###### construct the textual content model ###### \n",
    "\n",
    "for key,value in dict_a.items():\n",
    "    dict_m = {};\n",
    "    dict_result = {};\n",
    "    dict_result_2 = {};\n",
    "    dict_result_3 = {};\n",
    "    dict_result_4 = {};\n",
    "    candidate2 = []\n",
    "    \n",
    "##### construct the experiment dataset for each ground truth ########\n",
    "\n",
    "    test_time = pandas.to_datetime(dict_t[key][0])\n",
    "    days = datetime.timedelta(x) # tune time intervals [2,7,14,30] \n",
    "    new_test = test_time - days\n",
    "    interval = (pandas.to_datetime(train['ch_createdTime']) < test_time) & (pandas.to_datetime(train['ch_createdTime']) > new_test)\n",
    "    train_new = train.loc[interval]\n",
    "    index = train_new.index\n",
    "    number_of_rows = len(index)\n",
    "    train_m = []\n",
    "    for index, rows in train_new.iterrows(): \n",
    "        list_pattern =[rows.ch_changeId, rows.f_fileName, rows.ch_createdTime] \n",
    "        train_m.append(list_pattern)\n",
    "##### apply string techniques and combination method ##########\n",
    "\n",
    "    for row_m in train_m:\n",
    "        if row_m[0] not in dict_m:\n",
    "            dict_m[row_m[0]] = [];\n",
    "        dict_m[row_m[0]].append(row_m[1]);\n",
    "    \n",
    "    score_LCP = {};\n",
    "    score_LCSuff = {};\n",
    "    score_LCSubstr = {};\n",
    "    score_LCSubseq = {};\n",
    "\n",
    "    for key_m,value_m in dict_m.items():\n",
    "        sc1 = 0;\n",
    "        sc2 = 0;\n",
    "        sc3 = 0;\n",
    "        sc4 = 0;\n",
    "        for file in value:\n",
    "            for file_m in value_m:\n",
    "                sc1 = sc1 + filePathSimilarity_LCP(file,file_m);\n",
    "                sc2 = sc2 + filePathSimilarity_LCSuff(file, file_m);\n",
    "                sc3 = sc3 + filePathSimilarity_LCSubstr(file, file_m);\n",
    "                sc4 = sc4 + filePathSimilarity_LCSubseq (file, file_m);\n",
    "        sc1 = sc1 / (len(value) * len(value_m));\n",
    "        score_LCP[key_m] = sc1;\n",
    "        sc2 = sc2 / (len(value) * len(value_m));\n",
    "        score_LCSuff[key_m] = sc2;\n",
    "        sc3 = sc3 / (len(value) * len(value_m));\n",
    "        score_LCSubstr[key_m] = sc3;\n",
    "        sc4 = sc4 / (len(value) * len(value_m));\n",
    "        score_LCSubseq[key_m] = sc4;    \n",
    "    result1 = sort_by_value(score_LCP);\n",
    "    result2 = sort_by_value(score_LCSuff);\n",
    "    result3 = sort_by_value(score_LCSubstr);\n",
    "    result4 = sort_by_value(score_LCSubseq);\n",
    "    dict_result[key] = [];\n",
    "    dict_result_2[key] = [];\n",
    "    dict_result_3[key] = [];\n",
    "    dict_result_4[key] = [];\n",
    "    \n",
    "    for i in range(0,len(result1)):\n",
    "        dict_result[key].append(result1[i][0]);\n",
    "\n",
    "    for i in range(0,len(result2)):\n",
    "        dict_result_2[key].append(result2[i][0]);\n",
    "    for i in range(0,len(result3)):\n",
    "        dict_result_3[key].append(result3[i][0]);\n",
    "    for i in range(0,len(result4)):\n",
    "        dict_result_4[key].append(result4[i][0]);\n",
    "\n",
    "    score_dic_top = borda_count(dict_result, dict_result_2, dict_result_3, dict_result_4,len(result1))\n",
    "    \n",
    "###### retrieve Top-10 candidate list and do the matching whether or not each ground truth is detected #######  \n",
    "\n",
    "    for key in score_dic_top:\n",
    "        length =  len(score_dic_top[key])\n",
    "    \n",
    "    for i in range(0,length):\n",
    "        candidate2.extend([str(score_dic_top[key][i])])\n",
    "        \n",
    "    candidate_all2.append(candidate2)\n",
    "    \n",
    "    for row in checklist:\n",
    "            \n",
    "            if row[0] in score_dic_top:\n",
    "\n",
    "                if row[1] in score_dic_top[row[0]][0]:\n",
    "\n",
    "                    position.append(1)\n",
    "                    hit.append(int(row[0]))\n",
    "                    count.append(1)\n",
    "                elif row[1] in score_dic_top[row[0]][1]:\n",
    "\n",
    "                     position.append(2)\n",
    "                     hit.append(int(row[0]))\n",
    "                     count.append(1)\n",
    "                elif row[1] in score_dic_top[row[0]][2]:\n",
    "\n",
    "                     position.append(3)\n",
    "                     hit.append(int(row[0]))\n",
    "                     count.append(1)\n",
    "                elif row[1] in score_dic_top[row[0]][3]:\n",
    "\n",
    "                     position.append(4)\n",
    "                     hit.append(int(row[0]))\n",
    "                     count.append(1)\n",
    "                elif row[1] in score_dic_top[row[0]][4]:\n",
    "\n",
    "                     position.append(5)\n",
    "                     hit.append(int(row[0]))\n",
    "                     count.append(1)\n",
    "                elif row[1] in score_dic_top[row[0]][5]:\n",
    "\n",
    "                     position.append(6)\n",
    "                     hit.append(int(row[0]))\n",
    "                     count.append(1)\n",
    "                elif row[1] in score_dic_top[row[0]][6]:\n",
    "                     position.append(7)\n",
    "                     hit.append(int(row[0]))\n",
    "                     count.append(1)\n",
    "                elif row[1] in score_dic_top[row[0]][7]:\n",
    "                     position.append(8)\n",
    "                     hit.append(int(row[0]))\n",
    "                     count.append(1)\n",
    "                elif row[1] in score_dic_top[row[0]][8]:\n",
    "                     position.append(9)\n",
    "                     hit.append(int(row[0]))\n",
    "                     count.append(1)\n",
    "                elif row[1] in score_dic_top[row[0]][9]:\n",
    "                     position.append(10)\n",
    "                     hit.append(int(row[0]))\n",
    "                     count.append(1)\n",
    "                else:\n",
    "                    position.append(0)\n",
    "                    hit.append(int(row[0]))\n",
    "                    count.append(0)\n",
    "                    \n",
    "    print (key,number_of_rows) \n",
    "\n",
    "##### get the Top 10 candidates from the file location model ########    \n",
    "candidate_patch2 = dict(zip(hit,candidate_all2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using combination method to combine two Top-10 candidate lists from two models using assigned scores and time order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_patch = dict(sorted(candidate_patch.items(), key=operator.itemgetter(0)))\n",
    "candidate_patch2 = dict(sorted(candidate_patch2.items(), key=operator.itemgetter(0)))\n",
    "\n",
    "score_sor = copy.deepcopy(candidate_patch)\n",
    "\n",
    "for key in score_sor:\n",
    "    score_sor[key] = defaultdict(list)\n",
    "\n",
    "######## assign scores to two candidate lists from two single models #####\n",
    "\n",
    "for key in candidate_patch:\n",
    "    point = len(candidate_patch[key])\n",
    "    for i in candidate_patch[key]:\n",
    "        score_sor[key][i].append(point - candidate_patch[key].index(i))\n",
    "    for i in candidate_patch2[key]:\n",
    "        score_sor[key][i].append(point - candidate_patch2[key].index(i))\n",
    "\n",
    "######## use time order to deal with those candidates with same scores and retrieve Top 10 candidates######        \n",
    "score_dic_top = copy.deepcopy(score_sor)\n",
    "\n",
    "for key in score_sor:\n",
    "    sum_coms = []\n",
    "    for key2 in score_sor[key]:\n",
    "        sum_coms.append([key2, sum(score_sor[key][key2])])\n",
    "    for item in sum_coms:\n",
    "        item.append(dict_tc[item[0]])\n",
    "    sum_coms.sort(key=lambda x: [x[1],x[2]],reverse=True)\n",
    "    sum_coms = sum_coms[:10]\n",
    "    for item in sum_coms:\n",
    "        item =item.pop()\n",
    "    sum_coms = np.array(sum_coms)\n",
    "    sum_coms,a = np.hsplit(sum_coms,2)\n",
    "    score_dic_top[key] = [j for sub in sum_coms for j in sub]\n",
    "\n",
    "###### do the matching whether or not each ground truth is detected #######    \n",
    "\n",
    "check = list(csv.reader(open(''))) #impot pair_match file in the either file location or textual content folder\n",
    "check.pop(0)\n",
    "count = []\n",
    "hit = []\n",
    "position = []\n",
    "for row in check:\n",
    "    if int(row[0]) in score_dic_top:\n",
    "\n",
    "        if row[1] in score_dic_top[int(row[0])][0]:\n",
    "\n",
    "            position.append(1)\n",
    "            hit.append(row[0])\n",
    "            count.append(1)\n",
    "        elif row[1] in score_dic_top[int(row[0])][1]:\n",
    "\n",
    "             position.append(2)\n",
    "             hit.append(row[0])\n",
    "             count.append(1)\n",
    "        elif row[1] in score_dic_top[int(row[0])][2]:\n",
    "\n",
    "             position.append(3)\n",
    "             hit.append(row[0])\n",
    "             count.append(1)\n",
    "        elif row[1] in score_dic_top[int(row[0])][3]:\n",
    "\n",
    "             position.append(4)\n",
    "             hit.append(row[0])\n",
    "             count.append(1)\n",
    "        elif row[1] in score_dic_top[int(row[0])][4]:\n",
    "\n",
    "             position.append(5)\n",
    "             hit.append(row[0])\n",
    "             count.append(1)\n",
    "        elif row[1] in score_dic_top[int(row[0])][5]:\n",
    "\n",
    "             position.append(6)\n",
    "             hit.append(row[0])\n",
    "             count.append(1)\n",
    "        elif row[1] in score_dic_top[int(row[0])][6]:\n",
    "             position.append(7)\n",
    "             hit.append(row[0])\n",
    "             count.append(1)\n",
    "        elif row[1] in score_dic_top[int(row[0])][7]:\n",
    "             position.append(8)\n",
    "             hit.append(row[0])\n",
    "             count.append(1)\n",
    "        elif row[1] in score_dic_top[int(row[0])][8]:\n",
    "             position.append(9)\n",
    "             hit.append(row[0])\n",
    "             count.append(1)\n",
    "        elif row[1] in score_dic_top[int(row[0])][9]:\n",
    "             position.append(10)\n",
    "             hit.append(row[0])\n",
    "             count.append(1)\n",
    "        else:\n",
    "\n",
    "            position.append(0)\n",
    "            hit.append(row[0])\n",
    "            count.append(0)\n",
    "######### do the mapping between ground truth and their ranks ########\n",
    "recall = dict(zip(hit, position))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Fisrt we map id and linkage type together, then calculate the precision #########\n",
    "######## Below we use the AOSP model results as a example ########\n",
    "######## 1. get all detected linkages in the rank intervals -> 2. count how many alternative solution linkages #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5405405405405406\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "interval_30_result = pd.read_excel('Replication-Patch-Linkage/Empirical Evaluation/Android/Reulsts_eg_AOSP/AOSP_all.xlsx', 'Interval_30_Com')\n",
    "rank = interval_30_result[interval_30_result['Rank'].between(1, 10)]\n",
    "precision = len(rank[rank['Linkage'] == 'Alternative Solutions'])/len(rank)\n",
    "print (precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
